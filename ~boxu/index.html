<!DOCTYPE html>
<html lang="en">

<head>
  <title>Bo Xu, SWJTU (徐博, 西南交通大学)</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="author" content="Bo Xu">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Bo Xu, SWJTU (徐博 西南交通大学)" />
  <meta name="keywords" content="vrlab, SWJTU, 徐博, 西南交通大学,point cloud processing, building reconstruction,segmentation, roof topology" />
  <link rel="shortcut icon" href="img/icon.jpeg">
  <link rel="stylesheet" href="https://apps.bdimg.com/libs/bootstrap/3.3.4/css/bootstrap.min.css">
  <script src="https://use.fontawesome.com/fea487d9b7.js"></script>
  <link rel="stylesheet" href="css/perfect-scrollbar-0.4.5.min.css">
  <link rel="stylesheet" href="css/magnific-popup.css">
  <link rel="stylesheet" href="css/style.css">
  <link id="theme-style" rel="stylesheet" href="css/styles/default.css">
  <script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.js"></script>
  <script type="text/javascript" src="js/TweenMax.min.js"></script>
  <script type="text/javascript" src="js/jquery.touchSwipe.min.js"></script>
  <script type="text/javascript" src="js/jquery.carouFredSel-6.2.1-packed.js"></script>
  <script type="text/javascript" src="js/modernizr.custom.63321.js"></script>
  <script type="text/javascript" src="js/jquery.dropdownit.js"></script>
  <script type="text/javascript" src="js/jquery.stellar.min.js"></script>
  <script type="text/javascript" src="js/ScrollToPlugin.min.js"></script>
  <script src="https://apps.bdimg.com/libs/bootstrap/3.3.4/js/bootstrap.js"></script>
  <script type="text/javascript" src="js/jquery.mixitup.min.js"></script>
  <script type="text/javascript" src="js/masonry.min.js"></script>
  <script type="text/javascript" src="js/perfect-scrollbar-0.4.5.with-mousewheel.min.js"></script>
  <script type="text/javascript" src="js/jquery.magnific-popup.min.js"></script>
  <script type="text/javascript" src="js/jquery.stellar.min.js"></script>
  <script type="text/javascript" src="js/custom.js"></script>
  <link rel="stylesheet" href="custom-style.css">
  <script type="text/javascript" src="custom-style.js"></script>
</head>

<body>
  <div id="wrapper">
    <a href="#sidebar" class="mobilemenu">
      <i class="fa fa-th"></i>
    </a>
    <div id="sidebar">
      <div id="main-nav">
        <div id="nav-container">
          <div id="profile" class="clearfix">
            <div class="portrate hidden-xs"></div>
            <div class="title">
              <h2>Bo Xu (徐博)</h2>
              <h3>Southwest Jiaotong University</h3>
            </div>
          </div>
          <ul id="navigation">
            <li>
              <a href="#biography">
                <div class="icon fa fa-user"></div>
                <div class="text">About Me</div>
              </a>
            </li>
            <li>
              <a href="#research">
                <div class="icon fa fa-book"></div>
                <div class="text">Research</div>
              </a>
            </li>
            <li>
              <a href="#publications">
                <div class="icon fa fa-edit"></div>
                <div class="text">Publications</div>
              </a>
            </li>
            <li>
              <a href="#contact">
                <div class="icon fa fa-calendar"></div>
                <div class="text">Contact & Meet Me</div>
              </a>
            </li>
          </ul>
        </div>
      </div>
      <div class="social-icons">
        <ul>
          <li>
            <a href="mailto:bobxu.purdue@gmail.com">
              <i class="fa fa-envelope"></i>
            </a>
          </li>
        </ul>
      </div>
    </div>
    <div id="main">
      <div id="biography" class="page home" data-pos="home">
        <div class="pageheader">
          <div class="headercontent">
            <div class="section-container">
              <div class="row">
                <div class="col-sm20 visible-sm"></div>
                <div class="col-sm-8 col-md-7">
                  <div class="biothumb">
                    <img alt="image" src="img/play1.jpg" class="img-responsive">
                    <div class="overlay">
                      <h4>Bo Xu</h4>
                      <h5>Research Assistant</h5>
                      <ul class="list-unstyled">
                        <li>Faculty of Geosciences and Environmental Engineering</li>
                        <li>Southwest Jiaotong University</li>
                      </ul>
                    </div>
                  </div>
                </div>
                <div class="clearfix visible-sm visible-xs"></div>
                <div class="col-sm-12 col-md-5">
                  <h3 class="title">Bio</h3>
                  <p>I'm now a Research Assistant in the
                    <a href="https://gsee.swjtu.edu.cn/en/" target="_blank"> Faculty of Geosciences and Environmental
                      Engineering</a> of the Southwest Jiaotong University in Chengdu, China. I was
                    working as a Postdoctoral Fellow for the 
                    <a href="https://www.purdue.edu" target="_blank">Purdue University (USA)</a>.                    
                    during Nov.2017 to Jan.2019, under the supervision of
                    <a href="https://www.researchgate.net/profile/Jie_Shan" target="_blank">Prof. Jie Shan</a>.
                    Before that, I have spent 10 years to study Photogrammetry and Remote Sensing in Wuhan
                    University, where I have recieved my bachelor degree in the
                    <a href="http://www.sgg.whu.edu.cn/" target="_blank">School of Geomatics and Geodesy
                    </a> from Sep.2007-Jun.2011 and Ph.D in the
                    <a href="http://www.lmars.whu.edu.cn/" target="_blank">State Key Laboratory of Information
                      Engineering in Surveying, Mapping and Remote Sensing</a> from Sep.2011-Jun.2017 under the
                    supervision of
                    <a href="http://openrs.whu.edu.cn/wiki/index.php?title=OpenRS%3A%E7%A4%BE%E5%8C%BA" target="_blank">Prof. Wanshou Jiang</a>.
                  </p>
                  <p>I'm now focusing on 3D reconstruction of our planet earth globally and regionally using datasets
                    collected from the satellites, aircrafts, drones, vehicles, backpacks and hand-held
                    devices.</p>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="pagecontents">
          <div class="section color-1">
            <div class="section-container">
              <div class="row">
                <div class="col-md-6 col-md-offset-1">
                  <div class="title text-center">
                    <h3>Academic Positions</h3>
                  </div>
                  <ul class="ul-dates">
                    <li>
                      <div class="dates">
                        <span>now</span>
                        <span>2019</span>
                      </div>
                      <div class="content">
                        <h4>Research Assistant</h4>
                        <p>Faculty of Geosciences and Environmental Engineering
                          <em>
                            <br>Southwest Jiaotong University
                          </em>
                        </p>
                      </div>
                    </li>
                    <li>
                      <div class="dates">
                        <span>2019</span>
                        <span>2017</span>
                      </div>
                      <div class="content">
                        <h4>Postdoctoral Fellow</h4>
                        <p>Civil Engineering
                          <em>
                            <br>Purdue University, USA
                          </em>
                        </p>
                      </div>
                    </li>
                  </ul>
                </div>
                <div class="col-md-5">
                  <div class="title text-center">
                    <h3>Education & Training</h3>
                  </div>
                  <ul class="ul-dates">
                    <li>
                      <div class="dates">
                        <span>2017</span>
                        <span>2011</span>
                      </div>
                      <div class="content">
                        <h4>PhD candidates</h4>
                        <p>State Key Laboratory of Surveying Mapping and Remote Sensing
                          <em>
                            <br>Wuhan University
                          </em>
                        </p>
                      </div>
                    </li>
                    <li>
                      <div class="dates">
                        <span>2011</span>
                        <span>2007</span>
                      </div>
                      <div class="content">
                        <h4>Undergraduate student</h4>
                        <p>School of Geomatics and Geodesy
                          <em>
                            <br>Wuhan University
                          </em>
                        </p>
                      </div>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
          <div class="section color-2">
            <div class="section-container">
              <div class="row">
                <div class="col-md-10 col-md-offset-1">
                  <div class="title text-center">
                    <h3>Honors, Awards and Grants</h3>
                  </div>
                  <ul class="timeline">
                    <li class="open">
                      <div class="date">
                        <span>2018</span>
                      </div>
                      <div class="circle"></div>
                      <div class="data">
                        <div class="subject">Best paper award in CVPR Workshop EarthVision 2019(最佳论文奖，CVPR2019地球观测工作组)
                        </div>
                        <div class="text row">
                          <div class="col-md-12">
                            <p>Awarded to our paper "Urban Semantic 3D Reconstruction from Multiview Satellite Imagery"</p>
                          </div>
                        </div>
                      </div>
                    </li>        
                    <li>
                      <div class="date">Sept. 2011</div>
                      <div class="circle"></div>
                      <div class="data">
                        <div class="subject">The Freshman Scholarship</div>
                        <div class="text row">
                          <div class="col-md-12"> Rank 2st in the graduate entrance examination for the State Key
                            Laboratory of Surveying Mapping and Remote Sensing. And this shcolarship is granted to
                            six out of more than 100 graduate students.
                          </div>
                        </div>
                      </div>
                  </ul>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div id="research" class="page">
        <div class="pageheader">
          <div class="headercontent">
            <div class="section-container">
              <h2 class="title">Research Summary</h2>
              <div class="row">
                <div class="col-md-8">
                  <p>
                    The reconstruction of urban city remains a hot topic in the past 3 decades. 
                    Topic like digital city or smart city and applications developed basic on this have draw numerous attentions, 
                    range from the planning and management of the goverment to industry usage like the VR games and digital maps.
                    The 3D vector models are the most important fundamental data source that directly determine the quality and cost of the whole system.
                    Even when only consider the market within China, the total amount are estimated as "hundreds of billions".
                    Though the data source for urban reconstruction can be various, current research mainly concentrate the processing of point cloud,
                    either from LiDAR or matched by stereo image, and the observation platform may range from ground, aerial to satellite. 
                    As a result, our research will focus on the theory, algorithm and applications related to the processing of point clouds.</p></p>
                    
                    The data source we use:</p>
                    <ul>
                        <li>LiDAR: from both ground and aerial.</li>
                        <li>Stereo point cloud: Ranging from ground, aerial(including UAVs) to satellite imagery.</li>
                        <li>RGB-D camera.</li>
                      </ul>                 
                    The targets we are interested in:</p>
                    <ul>
                        <li>Urban buildings.</li>
                        <li>Road and bridges.</li>
                        <li>Electric power tower.</li>
                      </ul> 
                    Related techniques or skills:</p>
                    <ul>
                        <li>the C++ programming, including the use of the PCL, GDAL, CGAL library and the skills of plug-in developments.</li>
                        <li>The theory and skills for point cloud processing, i.e., segmentation, object detection, topology analysis of complex man-made objects.</li>
                        <li>Basic image processing skills, like the use of OpenCV (and OpenRS if you are interested in MPI)</li>
                        <li>the deep learning tools, i.e., the deep CNNs and the networks special for point cloud, like pointNet.</li>
                      </ul> 
                </div>
                <div class="col-md-4">
                  <div class="subtitle text-center">
                    <h3>Interests</h3>
                  </div>
                  <ul class="ul-boxed list-unstyled">
                    <li>Point Cloud Processing</li>
                    <li>Building Reconstruction</li>
                    <li>Satellite Imagery Processing</li>
                    <li>Computation Geometry</li>
                    <li>Object Extraction</li>
                    <li>Machine Learning</li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="pagecontents">
          <div class="section color-2">
            <div class="section-container">
              <div class="title text-center">
                <h3>Research Projects</h3>
              </div>
              <div class="row">
                <div class="col-md-12">
                  <ul class="ul-withdetails">
                    <li>
                      <div class="row">
                        <div class="col-sm-6 col-md-3">
                          <div class="image">
                            <img alt="image" src="img/topFig.png" class="img-responsive">
                            <div class="imageoverlay">
                              <i class="fa fa-search"></i>
                            </div>
                          </div>
                        </div>
                        <div class="col-sm-6 col-md-9">
                          <div class="meta">
                            <h3>Research project</h3>
                          </div>
                        </div>
                      </div>
                      <div class="details">
                        <ul class="ul-dates">
                          <li>
                            <div class="dates">
                              <span>2022/12</span>
                              <span>2020/01</span>
                            </div>
                            <div class="content">
                              <h4>National Natural Science Foundation of China (自然科学基金青年项目)</h4>
                              <p>Research on the hierarchical topology identification and model reconstruction of large area urban city from aerial point clouds,
                                <strong>PI</strong>
                              </p>
                            </div>
                          </li>
                          <li>
                            <div class="dates">
                              <span>2018/12</span>
                              <span>2017/11</span>
                            </div>
                            <div class="content">
                                <h4>  
                                     <a target="_blank" href="https://www.iarpa.gov/index.php/research-programs/core3d">IARPA: Creation of Operationally Realistic 3D Environment(core3D) project,USA
                                     </a>
                                  </h4>
                              <p> DANESFIELD: DAta Nexus for Estimating Semantics and Fusing Inferred Exterior Layers in 3D,
                                <strong>Join</strong>
                              </p>
                            </div>
                          </li>
                          <li>
                              <div class="dates">
                                <span>2017/12</span>
                                <span>2012/11</span>
                              </div>
                              <div class="content">
                                <h4>National Basic Research Program of China (973)</h4>
                                <p> 3D Reconstruction of Natural Terrain and Man-made Objects from High-resolution Remote Sensing Image,
                                  <strong>Join</strong>
                                </p>
                              </div>
                            </li>
                            <li>
                                <div class="dates">
                                  <span>2016</span>
                                  <span>2014</span>
                                </div>
                                <div class="content">
                                  <h4>China Southern Power Grid corporation</h4>
                                  <p> Aerial Photogrammetry and 3D Modeling of Overhead Power Transmission Lines  and its Application in the Management of Power Transmission,
                                    <strong>Join</strong>
                                  </p>
                                </div>
                              </li>
                        </ul>
                      </div>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div id="publications" class="page">
        <div class="page-container">
          <div class="pageheader">
            <div class="headercontent">
              <div class="section-container">
                <h2 class="title">Selected Publications</h2>
              </div>
            </div>
          </div>
          <div class="pagecontents">
            <div class="section color-1" id="filters">
              <div class="section-container">
                <div class="row">
                  <div class="col-md-3">
                    <h3>Filter by year:</h3>
                  </div>
                  <div class="col-md-6">
                    <select id="cd-dropdown" name="cd-dropdown" class="cd-select">
                      <option class="filter" value="all" selected>All years</option>
                      <option class="filter" value="2019">2019</option>
                      <option class="filter" value="2018">2018</option>
                      <option class="filter" value="2017">2017</option>
                      <option class="filter" value="2016">2016</option>
                      <option class="filter" value="2015">2015</option>
                    </select>
                  </div>
                  <div class="col-md-3" id="sort">
                    <span>Sort by year:</span>
                    <div class="btn-group pull-right">
                      <button type="button" data-sort="data-year" data-order="desc" class="sort btn btn-default">
                        <i class="fa fa-sort-numeric-asc"></i>
                      </button>
                      <button type="button" data-sort="data-year" data-order="asc" class="sort btn btn-default">
                        <i class="fa fa-sort-numeric-desc"></i>
                      </button>
                    </div>
                  </div>
                </div>
              </div>
            </div>
            <div class="section color-2" id="pub-grid">
              <div class="section-container">
                <div class="row">
                  <div class="col-md-12">
                    <div class="pitems">
                      <div class="item mix 2019" data-year="2019">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                              <i class="fa fa-expand"></i>
                            </a>
                            <a href="http://openaccess.thecvf.com/content_CVPRW_2019/html/EarthVision/Leotta_Urban_Semantic_3D_Reconstruction_From_Multiview_Satellite_Imagery_CVPRW_2019_paper.html" class="tooltips" title="External link"
                              target="_blank">
                              <i class="fa fa-external-link"></i>
                            </a>
                            <a href="http://www.chengjianglong.com/publications/Danesfield.pdf" class="tooltips" title="Download"
                              target="_blank">
                              <i class="fa fa-cloud-download"></i>
                            </a>
                          </div>
                          <h4 class="pubtitle">Urban Semantic 3D Reconstruction from Multiview Satellite Imagery</h4>
                          <div class="pubauthor">M. Leotta, C. Long, etc., <strong>B., Xu.</strong>
                          </div>
                          <div class="pubcite">
                            <span class="label label-success">Conference Papers (Best Paper Award)</span>CVPR workshop EarthVision, Long beach, USA, 2019.
                          </div>
                        </div>
                        <div class="pubdetails">
                            <h4>Abstract</h4>
                            <p>Methods for automated 3D urban modeling typically result in very dense point clouds or surface meshes derived from either overhead lidar or imagery (multiview stereo). Such models are very large and have no semantic separation of individual structures (i.e. buildings, bridges) from the terrain. Furthermore, such dense models often appear "melted" and do not capture sharp edges. This paper demonstrates an end-to-end system for segmenting buildings and bridges from terrain and estimating simple, low polygon, textured mesh models of these structures. The approach uses multiview-stereo satellite imagery as a starting point, but this work focuses on segmentation methods and regularized 3D surface extraction. Our work is evaluated on the IARPA CORE3D public data set using the associated ground truth and metrics. A web-based application deployed on AWS runs the algorithms and provides visualization of the results. Both the algorithms and web application are provided as open source software as a resource for further research or product development. </p>
                          </div>
                      </div>   
                                            
                      <div class="item mix 2019" data-year="2019">
                        <div class="pubmain">
                          <div class="pubassets">
                            <a href="#" class="pubcollapse">
                              <i class="fa fa-expand"></i>
                            </a>
                            <a href="https://www.researchgate.net/publication/333636066_GEOMETRIC_OBJECT_BASED_BUILDING_RECONSTRUCTION_FROM_SATELLITE_IMAGERY_DERIVED_POINT_CLOUDS" class="tooltips"
                              title="External link" target="_blank">
                              <i class="fa fa-external-link"></i>
                            </a>
                            <a href="https://engineering.purdue.edu/~jshan/publications/2019/607%20ISPRS%20GeospatialWeek%20Geometric%20Object%20Based%20Building%20Reconstruction%20from%20Satellite%20Imagery%20Derived%20Point%20Clouds%20%20Extended%20Abstract.pdf"
                              class="tooltips" title="Download" target="_blank">
                              <i class="fa fa-cloud-download"></i>
                            </a>
                          </div>
                          <h4 class="pubtitle">Geometric Object Based Building Reconstruction From Satelite Imagery Derived Point Clouds</h4>
                          <div class="pubauthor">
                              Z. Li, <strong>B., Xu.</strong>, J. Shan, 2019.
                          </div>
                          <div class="pubcite">
                            <span class="label label-success">Conference Papers</span> ISPRS conference，Volume XLII-2/W13, Enschede, the Netherlands, 2019.
                          </div>
                        </div>
                        <div class="pubdetails">
                          <h4>Abstract</h4>
                          <p>3D building models are digital models of urban areas that represent buildings, which have important role in urban planning and
                              smart city. Their components are described and represented by corresponding 2D and 3D spatial data and geo-referenced data.
                              Those models can be generated from stereo aerial images, satellite images or LiDAR point cloud. In this paper, we propose a
                              geometric object based building reconstruction method. The paper is structured as three parts: the first part introduces our
                              motivation and related work, the second part introduces the methodology and processes we used and the third part is about the test
                              result. Results from the point clouds generated from WorldView high resolution satellite images are used to demonstrate the
                              performance of our approach. </p>
                        </div>
                      </div>

                      <div class="item mix 2019" data-year="2019">
                          <div class="pubmain">
                            <div class="pubassets">
                              <a href="#" class="pubcollapse">
                                <i class="fa fa-expand"></i>
                              </a>
                              <a href="https://arxiv.org/abs/1904.08537" class="tooltips"
                                title="External link" target="_blank">
                                <i class="fa fa-external-link"></i>
                              </a>
                              <a href="https://arxiv.org/pdf/1904.08537"
                                class="tooltips" title="Download" target="_blank">
                                <i class="fa fa-cloud-download"></i>
                              </a>
                            </div>
                            <h4 class="pubtitle">Material Segmentation of Multi-View Satellite Imagery</h4>
                            <div class="pubauthor">
                                M. Purri, J. Xue, .etc. <strong>B., Xu.</strong>, J. Shan, 2019.
                            </div>
                            <div class="pubcite">
                              <span class="label label-success">preprint at arXiv
                            </div>
                          </div>
                          <div class="pubdetails">
                            <h4>Abstract</h4>
                            <p>Material recognition methods use image context and local cues for pixel-wise classification. In many cases only a single image is available to make a material prediction. Image sequences, routinely acquired in applications such as mutliview stereo, can provide a sampling of the underlying reflectance functions that reveal pixel-level material attributes. We investigate multi-view material segmentation using two datasets generated for building material segmentation and scene material segmentation from the SpaceNet Challenge satellite image dataset. In this paper, we explore the impact of multi-angle reflectance information by introducing the \textit{reflectance residual encoding}, which captures both the multi-angle and multispectral information present in our datasets. The residuals are computed by differencing the sparse-sampled reflectance function with a dictionary of pre-defined dense-sampled reflectance functions. Our proposed reflectance residual features improves material segmentation performance when integrated into pixel-wise and semantic segmentation architectures. At test time, predictions from individual segmentations are combined through softmax fusion and refined by building segment voting. We demonstrate robust and accurate pixelwise segmentation results using the proposed material segmentation pipeline. </p>
                          </div>
                        </div> 
                      <div class="item mix 2017" data-year="2017">
                          <div class="pubmain">
                            <div class="pubassets">
                              <a href="#" class="pubcollapse">
                                <i class="fa fa-expand"></i>
                              </a>
                              <a href="https://www.mdpi.com/2072-4292/9/9/936" class="tooltips" title="External link"
                                target="_blank">
                                <i class="fa fa-external-link"></i>
                              </a>
                              <a href="https://www.mdpi.com/2072-4292/9/9/936/pdf" class="tooltips" title="Download"
                                target="_blank">
                                <i class="fa fa-cloud-download"></i>
                              </a>
                            </div>
                            <h4 class="pubtitle">A Convolutional Neural Network based 3D Semantic Labeling Method for ALS Point Clouds</h4>
                            <div class="pubauthor">Z. Yang, W. Jiang *,<strong>B., Xu.</strong>, Q. Zhu, S. Jiang, W. Huang.
                            </div>
                            <div class="pubcite">
                              <span class="label label-success">Journal Papers</span>Remote Sensing,vol.9, p.9, 2017.
                            </div>
                          </div>
                          <div class="pubdetails">
                              <h4>Abstract</h4>
                              <p>3D semantic labeling is a fundamental task in airborne laser scanning (ALS) point clouds processing. The complexity of observed scenes and the irregularity of point distributions make this task quite challenging. Existing methods rely on a large number of features for the LiDAR points and the interaction of neighboring points, but cannot exploit the potential of them. In this paper, a convolutional neural network (CNN) based method that extracts the high-level representation of features is used. A point-based feature image-generation method is proposed that transforms the 3D neighborhood features of a point into a 2D image. First, for each point in the ALS data, the local geometric features, global geometric features and full-waveform features of its neighboring points within a window are extracted and transformed into an image. Then, the feature images are treated as the input of a CNN model for a 3D semantic labeling task. Finally, to allow performance comparisons with existing approaches, we evaluate our framework on the publicly available datasets provided by the International Society for Photogrammetry and Remote Sensing Working Groups II/4 (ISPRS WG II/4) benchmark tests on 3D labeling. The experiment results achieve 82.3% overall accuracy, which is the best among all considered methods. </p>
                            </div>
                        </div>   

                        <div class="item mix 2017" data-year="2017">
                            <div class="pubmain">
                              <div class="pubassets">
                                <a href="#" class="pubcollapse">
                                  <i class="fa fa-expand"></i>
                                </a>
                                <a href="https://www.mdpi.com/2072-4292/9/11/1172" class="tooltips" title="External link"
                                  target="_blank">
                                  <i class="fa fa-external-link"></i>
                                </a>
                                <a href="https://www.mdpi.com/2072-4292/9/11/1172/pdf" class="tooltips" title="Download"
                                  target="_blank">
                                  <i class="fa fa-cloud-download"></i>
                                </a>
                              </div>
                              <h4 class="pubtitle">A Heuristic Method for Power Pylon Reconstruction from Airborne LiDAR Date</h4>
                              <div class="pubauthor">R. Zhou, W. Jiang*, W. Huang, <strong>B., Xu.</strong> and S. Jiang.
                              </div>
                              <div class="pubcite">
                                <span class="label label-success">Journal Papers</span>Remote Sensing,vol.9, p.11, 2017.
                              </div>
                            </div>
                            <div class="pubdetails">
                                <h4>Abstract</h4>
                                <p>Object reconstruction from airborne LiDAR data is a hot topic in photogrammetry and remote sensing. Power fundamental infrastructure monitoring plays a vital role in power transmission safety. This paper proposes a heuristic reconstruction method for power pylons widely used in high voltage transmission systems from airborne LiDAR point cloud, which combines both data-driven and model-driven strategies. Structurally, a power pylon can be decomposed into two parts: the pylon body and head. The reconstruction procedure assembles two parts sequentially: firstly, the pylon body is reconstructed by a data-driven strategy, where a RANSAC-based algorithm is adopted to fit four principal legs; secondly, a model-driven strategy is used to reconstruct the pylon head with the aid of a predefined 3D head model library, where the pylon head’s type is recognized by a shape context algorithm, and their parameters are estimated by a Metropolis–Hastings sampler coupled with a Simulated annealing algorithm. The proposed method has two advantages: (1) optimal strategies are adopted to reconstruct different pylon parts, which are robust to noise and partially missing data; and (2) both the number of parameters and their search space are greatly reduced when estimating the head model’s parameters, as the body reconstruction results information about the original point cloud, and relationships between parameters are used in the pylon head reconstruction process. Experimental results show that the proposed method can efficiently reconstruct power pylons, and the average residual between the reconstructed models and the raw data was smaller than 0.3 m. </p>
                              </div>
                          </div>   

                        <div class="item mix 2017" data-year="2017">
                              <div class="pubmain">
                                <div class="pubassets">
                                  <a href="#" class="pubcollapse">
                                    <i class="fa fa-expand"></i>
                                  </a>
                                  <a href="http://www.mdpi.com/2072-4292/9/4/354" class="tooltips" title="External link"
                                    target="_blank">
                                    <i class="fa fa-external-link"></i>
                                  </a>
                                  <a href="http://www.mdpi.com/2072-4292/9/4/354/pdf" class="tooltips" title="Download"
                                    target="_blank">
                                    <i class="fa fa-cloud-download"></i>
                                  </a>
                                </div>
                                <h4 class="pubtitle">HRTT: A Hierarchical Roof Topology Structure for Robust Building Roof Reconstruction from Point Clouds</h4>
                                <div class="pubauthor"> <strong>B., Xu.</strong>, W. Jiang* and L. Li
                                </div>
                                <div class="pubcite">
                                  <span class="label label-success">Journal Papers</span>Remote Sensing,vol.9, p.4, 2017.
                                </div>
                              </div>
                              <div class="pubdetails">
                                  <h4>Abstract</h4>
                                  <p>The identification and representation of building roof topology are basic, but important, issues for 3D building model reconstruction from point clouds. Always, the roof topology is expressed by the roof topology graph (RTG), which stores the plane–plane adjacencies as graph edges. As the decision of the graph edges is often based on local statistics between adjacent planes, topology errors can be easily produced because of noise, lack of data, and resulting errors in pre-processing steps. In this work, the hierarchical roof topology tree (HRTT) is proposed, instead of traditional RTG, to represent the topology relationships among different roof elements. Building primitives or child structures are taken as inside tree nodes; thus, the plane–model and model–model relations can be well described and further exploited. Integral constraints and extra verifying procedures can also be easily introduced to improve the topology quality. As for the basic plane-to-plane adjacencies, we no longer decide all connections at the same time, but rather we decide the robust ones preferentially. Those robust connections will separate the whole model into simpler components step-by-step and produce the basic semantic information for the identification of ambiguous ones. In this way, the effects from structures of minor importance or spurious ridges can be limited to the building locale, while the common features can be detected integrally. Experiments on various data show that the proposed method can obviously improve the topology quality and produce more precise results. Compared with the RTG-based method, two topology quality indices increase from 80.9% and 79.8% to 89.4% and 88.2% in the test area. The integral model quality indices at the pixel level and the plane level also achieve the precision of 90.3% and 84.7%, accordingly. </p>
                                </div>
                          </div>   

                          <div class="item mix 2016" data-year="2016">
                                <div class="pubmain">
                                  <div class="pubassets">
                                    <a href="#" class="pubcollapse">
                                      <i class="fa fa-expand"></i>
                                    </a>
                                    <a href="https://www.mdpi.com/2072-4292/8/1/5" class="tooltips" title="External link"
                                      target="_blank">
                                      <i class="fa fa-external-link"></i>
                                    </a>
                                    <a href="https://www.mdpi.com/2072-4292/8/1/5/pdf" class="tooltips" title="Download"
                                      target="_blank">
                                      <i class="fa fa-cloud-download"></i>
                                    </a>
                                  </div>
                                  <h4 class="pubtitle">Investigation on the Weighted RANSAC Approaches for Building Roof Plane Segmentation from LiDAR Point Clouds</h4>
                                  <div class="pubauthor"> <strong>B., Xu.</strong>, W. Jiang*, J. Shan, J. Zhang and L. Li
                                  </div>
                                  <div class="pubcite">
                                    <span class="label label-success">Journal Papers</span>Remote Sensing,vol.8, p.1, 2016.
                                  </div>
                                </div>
                                <div class="pubdetails">
                                    <h4>Abstract</h4>
                                    <p> 
                                      RANdom SAmple Consensus (RANSAC) is a widely adopted method for LiDAR point cloud segmentation because of its robustness to noise and outliers. However, RANSAC has a tendency to generate false segments consisting of points from several nearly coplanar surfaces. To address this problem, we formulate the weighted RANSAC approach for the purpose of point cloud segmentation. In our proposed solution, the hard threshold voting function which considers both the point-plane distance and the normal vector consistency is transformed into a soft threshold voting function based on two weight functions. To improve weighted RANSAC’s ability to distinguish planes, we designed the weight functions according to the difference in the error distribution between the proper and improper plane hypotheses, based on which an outlier suppression ratio was also defined. Using the ratio, a thorough comparison was conducted between these different weight functions to determine the best performing function. The selected weight function was then compared to the existing weighted RANSAC methods, the original RANSAC, and a representative region growing (RG) method. Experiments with two airborne LiDAR datasets of varying densities show that the various weighted methods can improve the segmentation quality differently, but the dedicated designed weight functions can significantly improve the segmentation accuracy and the topology correctness. Moreover, its robustness is much better when compared to the RG method.
                                    </p>
                                  </div>
                          </div>

                          <div class="item mix 2015" data-year="2015">
                              <div class="pubmain">
                                <div class="pubassets">
                                  <a href="#" class="pubcollapse">
                                    <i class="fa fa-expand"></i>
                                  </a>
                                  <a href="http://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XL-4-W5/147/2015/" class="tooltips" title="External link"
                                    target="_blank">
                                    <i class="fa fa-external-link"></i>
                                  </a>
                                  <a href="https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XL-4-W5/147/2015/isprsarchives-XL-4-W5-147-2015.pdf" class="tooltips" title="Download"
                                    target="_blank">
                                    <i class="fa fa-cloud-download"></i>
                                  </a>
                                </div>
                                <h4 class="pubtitle">A Research on the Hierarchy and Completeness of Roof Topology for Robust Building Reconstruction from Airborne Point Cloud</h4>
                                <div class="pubauthor"> <strong>B., Xu.</strong>,  W. Jiang* and Q. Zhu
                                </div>
                                <div class="pubcite">
                                  <span class="label label-success">Conference Papers</span>ISPRS,XL-4-W5, Tokyo, Japan, 2017.
                                </div>
                              </div>
                              <div class="pubdetails">
                                  <h4>Abstract</h4>
                                  <p> In this work, we concentrate on the hierarchy and completeness of roof topology, and the aim is to avoid or correct the errors in roof topology. The hierarchy of topology is expressed by the hierarchical roof topology graph (HRTG) in accord with the definition of CityGML LOD (level of details). We decompose the roof topology graph (RTG) with a progressive approach while maintain the integrality and consistency of the data set simultaneously. Common feathers like collinear ridges or boundaries are calculated integrally to maintain their completeness. The roof items will only detected locally to decrease the error caused by data spare or mutual interference. Finally, a topology completeness test is adopted to detect and correct errors in roof topology, which results in a complete and hierarchical building model. Experiments shows that our methods have obvious improvements to the RTG based reconstruction method, especially for sparse data or roof topology with ambiguous. </p>
                                </div>
                          </div> 
                        
                        
                    </div>
                  </div>      
                </div>               
              </div>
            </div>
          </div>
        </div>
      </div>
      <div id="contact" class="page stellar">
        <div class="pageheader">
          <div class="headercontent">
            <div class="section-container">
              <h2 class="title">Contact</h2>
              <div class="row">
                <div class="col-md-7">
                  <h4>
                    <strong>Corresponding Address:</strong>
                  </h4>
                  <p>Dr. Bo Xu
                    <br />Room 6104, Faculty of Geosciences and Environmental Engineering
                    <br />Southwest Jiaotong University
                    <br />Xi'an Road, Gaoxin West District, Chengdu
                  </p>
                </div>
                <div class="col-md-5">
                  <ul class="list-unstyled">
                    <li>
                      <strong>
                        <i class="fa fa-envelope"></i>&nbsp;&nbsp;
                      </strong>
                      <span>
                        <a href="mailto:xubo@swjtu.edu.cn">xubo@swjtu.edu.cn</a>
                      </span>
                    </li>
                    <li>
                      <strong>
                        <i class="fa fa-envelope"></i>&nbsp;&nbsp;
                      </strong>
                      <span>
                        <a href="mailto:bobxu.purdue@gmail.com">bobxu.purdue@gmail.com</a>
                      </span>
                    </li>
                    <li>
                      <strong>
                        <i class="fa fa-weixin"></i>&nbsp;&nbsp;
                      </strong>
                      <span>Docxubo</span>
                    </li>
                    <li>
                      <strong>
                        <i class="fa fa-weixin"></i>&nbsp;&nbsp;
                      </strong>
                      <img src="img/qrcode.jpg" width="192" height="192">
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div id="overlay"></div>
    </div>
  </div>
</body>

</html>